{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1 align='center'>Cybersecurity threats detection using Deep Learning Architectures</h1>\n",
    "\n",
    "### Types of Attacks\n",
    "\n",
    "- *Denial of service attack (DoS)*: freezing or stopping the service permanently or temporarily, by sending a large amount of traffic\n",
    "- *Remote to local attack*: unauthorized access is granted by sending packets between the network and the system\n",
    "- *Probing*: information and data collected by scanning and mapping the network\n",
    "- *User to root attack*: normal users' password is traced\n",
    "- *Adversarial Attacks*: Deep Neural network are targeted by integrating noise in training data\n",
    "- *Integrity Attacks*: system data is corrupted or encrypted\n",
    "- *Causative Attacks*: neural network decision-making algorithm is attacked leading to miss-classification\n",
    "\n",
    "### USTC-TK2016 Dataset\n",
    "\n",
    "USTC-TK2016 is composed by a set of pcap files containing raw network traffic from 10 bening and 10 malware apps as shown at the table below:<br>\n",
    "![USTC-TK2016](data/img/USTC-TK2016.png)<br>\n",
    "\n",
    "### Approach\n",
    "\n",
    "- *CNN*: Pcap files will be transformed to mist images fed to CNN\n",
    "- *DNN~LSTM*: Argus api will be used to extract features from pcap files"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Malware Traffic Classification Using CNN\n",
    "\n",
    "##### Data preprocessing\n",
    "\n",
    "- Step 1: Install pre-requisites (DO NOT RUN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Connect to Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update the list of packages\n",
    "!sudo apt-get update\n",
    "# Install pre-requisite packages.\n",
    "!sudo apt-get install -y wget apt-transport-https software-properties-common\n",
    "# Download the Microsoft repository GPG keys\n",
    "!wget -q https://packages.microsoft.com/config/ubuntu/16.04/packages-microsoft-prod.deb\n",
    "# Register the Microsoft repository GPG keys\n",
    "!sudo dpkg -i packages-microsoft-prod.deb\n",
    "# Update the list of packages after we added packages.microsoft.com\n",
    "!sudo apt-get update\n",
    "# Install PowerShell\n",
    "!sudo apt-get install -y powershell\n",
    "# Install SplitCap pre-requisite\n",
    "!sudo apt install mono-runtime\n",
    "# Install find dupes\n",
    "!sudo apt-get install fdupes\n",
    "\n",
    "%cd drive/MyDrive/UNIPI/DL_Cybersecurity/\n",
    "# Clone the repository on \"ubuntu\" branch\n",
    "!sudo git clone -b ubuntu https://github.com/yungshenglu/USTC-TK2016 USTC-TK2016\n",
    "# Install the required packages\n",
    "!pip3 install -r requirements.txt\n",
    "# Download the traffic dataset\n",
    "%cd USTC-TK2016/1_Pcap/\n",
    "!sudo git clone -b master https://github.com/yungshenglu/USTC-TFC2016\n",
    "# Grand run permission to executable files\n",
    "%cd ../\n",
    "!chmod 777 0_Tool/SplitCap_2-1/SplitCap.exe\n",
    "!chmod 777 1_Pcap2Session.ps1\n",
    "!chmod 777 2_ProcessSession.ps1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Step 2: Split the PCAP files by each session (DO NOT RUN)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pwsh -File ./1_Pcap2Session.ps1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Step 3: Process Sessions  (DO NOT RUN)\n",
    "\n",
    "Top 60000 large PCAP files selected and trimmed and randomly distributed into test and train sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pwsh -File ./2_ProcessSession.ps1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Step 4: PCAP files converted to images (DO NOT RUN)\n",
    "\n",
    "Trimmed PCAP files into size is 784 bytes (28 x 28) (0x00 element is appended if the PCAP file is shorter than 784 bytes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python3 3_Session2Png.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Step 5: Png files are labeled and converted to IDX files (DO NOT RUN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python3 4_Png2Mnist.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training and Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'module' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-d0f34b50a8e9>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mmnist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmnist\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmnist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'module' has no len()"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "DATA_DIR = 'drive/MyDrive/UNIPI/DL_Cybersecurity/USTC-TK2016/5_Mnist/'\n",
    "dict_2class = {0:'Benign',1:'Malware'}\n",
    "dict_20class = {0:'BitTorrent',1:'Facetime',2:'FTP',3:'Gmail',4:'MySQL',5:'Outlook',6:'Skype',7:'SMB',8:'Weibo',9:'WorldOfWarcraft',10:'Cridex',11:'Geodo',12:'Htbot',13:'Miuref',14:'Neris',15:'Nsis-ay',16:'Shifu',17:'Tinba',18:'Virut',19:'Zeus'}\n",
    "\n",
    "\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "  \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  Values are rescaled from [0, 255] down to [0, 1].\n",
    "  \"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(16)\n",
    "    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    #data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "  return labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract it into np arrays.\n",
    "train_data = extract_data(DATA_DIR + 'train-images-idx3-ubyte.gz', 60000) / 250.0\n",
    "train_labels = extract_labels(DATA_DIR + 'train-labels-idx1-ubyte.gz', 60000)\n",
    "test_data = extract_data(DATA_DIR + 't10k-images-idx3-ubyte.gz', 10000) / 250.0\n",
    "test_labels = extract_labels(DATA_DIR + 't10k-labels-idx1-ubyte.gz', 10000)\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (train_data.shape, train_labels.shape))\n",
    "print('Test: X=%s, y=%s' % (test_data.shape, test_labels.shape))\n",
    "\n",
    "bitTorrentSamples = [train_data[i] for i in np.where(train_labels == 0)[0][:9]]\n",
    "cridexSamples = [train_data[i] for i in np.where(train_labels == 9)[0][:9]]\n",
    "samples = [train_data[i] for i in [np.where(train_labels == j)[0][0] for j in range(20)]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot BitTorrent (Benign) images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bitTorrentFig = make_subplots(\n",
    "    rows=3, cols=3\n",
    ")\n",
    "\n",
    "for i in range(9):\n",
    "  bitTorrentFig.add_trace(px.imshow(bitTorrentSamples[i], color_continuous_scale='gray').data[0], row=int(i/3)+1, col=i%3+1)\n",
    "\n",
    "bitTorrentFig.update_layout(title_text=\"BitTorrent (Benign) images\", title_xanchor=\"center\", title_yanchor=\"top\", title_x=0.5, title_y=0.9, height=700)\n",
    "coloraxis = px.imshow(bitTorrentSamples[0], color_continuous_scale='gray').layout.coloraxis\n",
    "bitTorrentFig.layout.coloraxis = coloraxis\n",
    "bitTorrentFig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot Cridex (Malware)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cridexFig = make_subplots(\n",
    "    rows=3, cols=3\n",
    ")\n",
    "\n",
    "for i in range(9):\n",
    "  cridexFig.add_trace(px.imshow(cridexSamples[i], color_continuous_scale='gray').data[0], row=int(i/3)+1, col=i%3+1)\n",
    "\n",
    "cridexFig.update_layout(title_text=\"Cridex (Malware) images\", title_xanchor=\"center\", title_yanchor=\"top\", title_x=0.5, title_y=0.9, height=700)\n",
    "coloraxis = px.imshow(cridexSamples[0], color_continuous_scale='gray').layout.coloraxis\n",
    "cridexFig.layout.coloraxis = coloraxis\n",
    "cridexFig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare Benign and Malware images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "benignFig = make_subplots(\n",
    "    rows=2, cols=5,\n",
    "    subplot_titles=([dict_20class.get(key) for key in range(10)]))\n",
    "\n",
    "malwareFig = make_subplots(\n",
    "    rows=2, cols=5,\n",
    "    subplot_titles=([dict_20class.get(key) for key in range(10,20)]))\n",
    "\n",
    "for i in range(10):\n",
    "  benignFig.add_trace(px.imshow(samples[i], color_continuous_scale='gray').data[0], row=int(i/5)+1, col=i%5+1)\n",
    "  malwareFig.add_trace(px.imshow(samples[i+10], color_continuous_scale='gray').data[0], row=int(i/5)+1, col=i%5+1)\n",
    "\n",
    "benignFig.update_layout(title_text=\"Benign images\", title_xanchor=\"center\", title_yanchor=\"top\", title_x=0.5, title_y=0.9, height=700)\n",
    "malwareFig.update_layout(title_text=\"Malware images\", title_xanchor=\"center\", title_yanchor=\"top\", title_x=0.5, title_y=0.9, height=700)\n",
    "coloraxis = px.imshow(samples[0], color_continuous_scale='gray').layout.coloraxis\n",
    "benignFig.layout.coloraxis = coloraxis\n",
    "malwareFig.layout.coloraxis = coloraxis\n",
    "benignFig.show()\n",
    "malwareFig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# Add a channels dimension\n",
    "#train_data = train_data[..., tf.newaxis].astype(\"float32\")\n",
    "#test_data = test_data[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "#map labels from 20 -> 2\n",
    "binary_train_labels = np.asarray([0 if l in range(10) else 1 for l in train_labels])\n",
    "binary_test_labels = np.asarray([0 if l in range(10) else 1 for l in test_labels])\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, 5, activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 5, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 5, activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.35),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = [10, 20, 40]\n",
    "LEARNING_RATE = [0.001, 0.0001]\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "\n",
    "for epoch in EPOCHS:\n",
    "  for lr in LEARNING_RATE:\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    results = model.fit(train_data, binary_train_labels, epochs=EPOCHS[0], batch_size=BATCH_SIZE, validation_data=(test_data, binary_test_labels), validation_batch_size=BATCH_SIZE)\n",
    "\n",
    "    model_name = 'model_' + str(epoch) + '_' + str(lr)\n",
    "\n",
    "    model.save('drive/MyDrive/UNIPI/DL_Cybersecurity/saved_model/' + model_name)\n",
    "\n",
    "    with open('drive/MyDrive/UNIPI/DL_Cybersecurity/saved_history/' + model_name, 'wb') as file_pi:\n",
    "      pickle.dump(results.history, file_pi)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}